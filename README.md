# Animal-Cafe-BI-Solution
End-to-end BI solution: Python data generation, SSIS ETL pipeline (SCD Type 2), SQL Server Data Warehouse, and Power BI analytics for an Animal Cafe.

Ez a projekt egy fikt√≠v √°llatos k√°v√©z√≥ teljes √ºzleti intelligencia (BI) megold√°s√°t mutatja be. A folyamat az adatgener√°l√°st√≥l kezdve, egy h√°romr√©teg≈± adatt√°rh√°z (DWH) fel√©p√≠t√©s√©n √©s SSIS alap√∫ ETL folyamatokon kereszt√ºl a Power BI vizualiz√°ci√≥ig tart.

## üöÄ Technol√≥giai Stack
*   **Adatgener√°l√°s:** Python (Faker k√∂nyvt√°r)
*   **Adatb√°zis:** Microsoft SQL Server
*   **ETL folyamatok:** Microsoft SSIS (SQL Server Integration Services)
*   **Adatmodellez√©s:** Csillags√©ma (Star Schema)
*   **Vizualiz√°ci√≥:** Power BI

---

## üìä 1. Adatforr√°s √©s Modellez√©s
A projekt alapj√°t egy Python scripttel gener√°lt rel√°ci√≥s adatb√°zis adja, amely egy k√°v√©z√≥ mindennapi m≈±k√∂d√©s√©t szimul√°lja (rendel√©sek, foglal√°sok, √°llatok eg√©szs√©g√ºgyi adatai, v√°s√°rl√≥k, el≈ëfizet√©sek).

**Forr√°s adatb√°zis modell:**
![K√âP: Itt a PDF 2. oldal√°n l√©v≈ë erd.dbdesigner-es modellt haszn√°ld](docs/images/source_db_model.png)

---

## üèóÔ∏è 2. Adatt√°rh√°z Architekt√∫ra (DWH)
A megold√°s egy klasszikus h√°romr√©teg≈± architekt√∫r√°ra √©p√ºl a maxim√°lis adatmin≈ës√©g √©s nyomonk√∂vethet≈ës√©g √©rdek√©ben:

### A. STAGE R√©teg
Az adatok egys√©ges√≠t√©se itt t√∂rt√©nik. Minden mez≈ë sz√∂veges (`string`) t√≠pus√∫, nincsenek k√©nyszerek (Constraints), √≠gy a bet√∂lt√©s gyors √©s hibat≈±r≈ë.
*   **C√©l:** A forr√°srendszer tehermentes√≠t√©se √©s az adatok gyors √°temel√©se.

### B. HST (History) R√©teg
Ebben a r√©tegben t√∂rt√©nik az adatok historiz√°l√°sa √©s az adatt√≠pusok v√©gleges√≠t√©se.
*   **SCD Type 2:** Minden t√°bla tartalmaz `START_DATE` √©s `END_DATE` mez≈ëket a v√°ltoz√°sok k√∂vet√©s√©re.
*   ![K√âP: PDF 5. oldali HST modell](docs/images/hst_model.png)

### C. DM (Data Mart) R√©teg
A v√©gfelhaszn√°l√≥k sz√°m√°ra el≈ëk√©sz√≠tett, Csillags√©m√°ba rendezett adatok.
*   **T√©nyt√°bla:** `FactSales` (√ârt√©kes√≠t√©sek)
*   **Dimenzi√≥k:** `DimProduct`, `DimCustomer`, `DimDate`
*   ![K√âP: PDF 6. oldali Csillags√©ma k√©p](docs/images/star_schema.png)

---

## üîÑ 3. ETL Folyamat (SSIS)
A teljes adatmozgat√°st **SQL Server Integration Services (SSIS)** csomagok v√©gzik.

### Extract folyamat
Minden fut√°s elej√©n egy `Execute SQL Task` ki√ºr√≠ti a STAGE t√°bl√°kat (`TRUNCATE`), majd felt√∂lti azokat az aktu√°lis adatokkal.
![K√âP: PDF 7. oldal, STAGE folyamat](docs/images/extract_process.png)

### Transform & Load
A historiz√°l√°s√©rt a **Slowly Changing Dimension (SCD)** komponens felel. A t√©nyt√°bla felt√∂lt√©sekor **Lookup** komponensek seg√≠ts√©g√©vel k√©pezz√ºk le az √ºzleti kulcsokat technikai kulcsokra (Surrogate Keys).
![K√âP: PDF 10. oldal, T√©ny t√°bla felt√∂lt√©se](docs/images/load_fact.png)

---

## üìà 4. Power BI Analitika
A Power BI riport az al√°bbi √ºzleti k√©rd√©sekre ad v√°laszt:
*   Melyek a legn√©pszer≈±bb term√©kkateg√≥ri√°k?
*   Hogyan alakul a bev√©tel szezonalit√°sa (negyed√©ves bont√°s)?
*   Kik a top v√°s√°rl√≥k √©s mik a kedvenc term√©keik?# Global Supply Chain & Sustainability BI Solution

**End-to-end Enterprise Data Warehouse (DWH) solution: Python data telemetry, SSIS ETL pipeline (SCD Type 2), SQL Server storage, and Power BI Analytics for Lifecycle Assessment (LCA).**

## üöÄ Project Overview
This project demonstrates a comprehensive Business Intelligence solution designed for a global manufacturing and supply chain network. It simulates real-time monitoring of factory emissions, material usage, and logistics efficiency.

The pipeline covers the entire data lifecycle:
1.  **Data Generation:** Synthetic telemetry simulating global factory nodes.
2.  **Data Warehousing:** A three-layer architecture (Stage, History, Data Mart).
3.  **ETL Orchestration:** Complex data transformation using SSIS.
4.  **Analytics:** Lifecycle Assessment (LCA) dashboarding.

---

## üõ†Ô∏è Technical Stack
*   **Data Generation:** Python (`Faker` library) - Simulating IoT sensor data & logistics logs.
*   **Database Engine:** Microsoft SQL Server (2019+).
*   **ETL Orchestration:** Microsoft SSIS (SQL Server Integration Services).
*   **Data Modeling:** Dimensional Modeling (Star Schema) & SCD Type 2.
*   **BI & Analytics:** Microsoft Power BI (DAX).

---

## üìä 1. Data Source & Modeling (Python)
The foundation is a Python-based telemetry engine that generates relational data simulating a global supply chain. Unlike static datasets, this script generates dynamic relationships between factories, materials, and energy consumption.

**Source Database Entities:**
*   **Factories:** Metadata about manufacturing locations.
*   **Materials:** Raw materials with specific carbon emission factors.
*   **Logistics:** Shipping routes and transport modes.
*   **Emission Logs:** Transactional data recording energy usage and CO2 output.

![Source DB Model](docs/images/source_db_model.png)

---

## üèóÔ∏è 2. Data Warehouse Architecture
The solution follows a classic **Three-Tier Architecture** to ensure high data quality, historical tracking, and query performance:

### A. STAGE Layer (Landing Zone)
*   **Purpose:** Raw data ingestion.
*   **Design:** All fields are handled as `strings` (varchar) with no constraints.
*   **Logic:** `TRUNCATE` + `INSERT` strategy for high-speed batch loading.

### B. HST (History) Layer - Core DWH
*   **Purpose:** Data type enforcement and historical tracking.
*   **Design:** Implements **Slowly Changing Dimensions (SCD Type 2)**.
*   **Logic:** Every dimension table tracks changes (e.g., if a factory changes its energy source) using `START_DATE`, `END_DATE`, and `IS_CURRENT` flags. This ensures a perfect audit trail for LCA reporting.

![HST Model](docs/images/hst_model.png)

### C. DM (Data Mart) Layer - Analytics
*   **Purpose:** Optimized for BI reporting.
*   **Design:** **Star Schema**.
*   **Fact Table:** `FactEmissions` (Contains measures: Energy usage, CO2 output).
*   **Dimensions:** `DimMaterial`, `DimFactory`, `DimLogistics`, `DimDate`.

![Star Schema](docs/images/star_schema.png)

---

## üîÑ 3. ETL Pipeline (SSIS Orchestration)
The integration logic is managed by **SQL Server Integration Services (SSIS)** packages.

### Extract & Load Phase
*   **Control Flow:** An `Execute SQL Task` performs a `TRUNCATE` on STAGE tables before each run.
*   **Data Flow:** Extracts fresh telemetry from the Python-generated source and loads it into the Staging area.

![Extract Process](docs/images/extract_process.png)

### Transformation Phase (SCD Logic)
*   **Historization:** Managed via **SCD Wizard** or custom Merge logic to handle historical updates.
*   **Surrogate Keys:** Uses **Lookup Transformations** to map business keys to technical Surrogate Keys, isolating the DWH from source system changes.

![Load Fact](docs/images/load_fact.png)

---

## üìà 4. Power BI Sustainability Analytics
The final dashboard provides critical insights for **LCA (Lifecycle Assessment)** practitioners:

*   **Carbon Footprint Trends:** Quarterly analysis of CO2 emissions across different manufacturing regions.
*   **Material Efficiency:** Identifying high-impact materials and suggesting sustainable alternatives based on historical data.
*   **Operational KPIs:**
    *   **Total Carbon Footprint (kg CO2e)**
    *   **Energy Intensity (kWh/Unit)**
    *   **Material Circularity Score**

![Power BI Dashboard](docs/images/powerbi_dashboard.png)

---

## ‚öôÔ∏è Setup & Execution

1.  **Database Initialization:**
    *   Run scripts in `/sql/01_create_source.sql` to setup the operational DB.
    *   Run `/sql/02_create_dwh.sql` to setup Stage, History, and Data Mart schemas.
2.  **Data Generation:**
    *   Execute `python scripts/data_generator.py` to populate the source system.
3.  **ETL Execution:**
    *   Open the SSIS project in Visual Studio.
    *   Configure `Connection Managers` for your local SQL Server instance.
    *   Execute the `Master_Package.dtsx` to trigger the full ETL cycle.
4.  **Analysis:**
    *   Open `reports/Sustainability_Dashboard.pbix` to explore the data.

**F≈ëbb √ºzleti mutat√≥k (KPI-ok):**
*   √ñsszes bev√©tel (Total Revenue)
*   Tranzakci√≥sz√°m (Transaction Count)
*   √Åtlagos kos√°r√©rt√©k (Avg Ticket Size)

![K√âP: PDF 12. vagy 15. oldal, a Dashboard-odr√≥l egy l√°tv√°nyos k√©p](docs/images/powerbi_dashboard.png)

---

## üõ†Ô∏è Telep√≠t√©s √©s Haszn√°lat
1.  Futtasd le a `/sql` mapp√°ban tal√°lhat√≥ t√°blal√©trehoz√≥ scripteket.
2.  Nyisd meg az SSIS projektet Visual Studio-ban.
3.  √Åll√≠tsd be a `Connection Manager`-ben a saj√°t SQL Server p√©ld√°nyodat.
4.  Futtasd le a csomagokat az adatok bet√∂lt√©s√©hez.
5.  Nyisd meg a Power BI f√°jlt az adatok elemz√©s√©hez.
